<!doctype html><html xmlns=http://www.w3.org/1999/xhtml xml:lang=en-us lang=en-us><head><link rel=stylesheet href=https://unpkg.com/spectre.css/dist/spectre.min.css><link rel=stylesheet href=https://unpkg.com/spectre.css/dist/spectre-exp.min.css><link rel=stylesheet href=https://unpkg.com/spectre.css/dist/spectre-icons.min.css><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.6.0/styles/nnfx-dark.min.css><link rel=stylesheet href=https://pro.fontawesome.com/releases/v5.10.0/css/all.css integrity=sha384-AYmEC3Yw5cVb3ZcuHtOA93w35dYTsvhLPVnYs9eStHfGJvOvKxVfELGroGkvsg+p crossorigin=anonymous><link href=https://gmpg.org/xfn/11 rel=profile><meta charset=utf-8><meta name=generator content="Hugo 0.83.1"><meta name=viewport content="width=device-width,initial-scale=1"><title>[K8s] Learn Kubernetes HA Architecture with Hands-On Example &#183; Ming's Site</title><meta name=description content="Learn Kubernetes HA Architecture with Hands-On Example."><link type=text/css rel=stylesheet href=https://minghsu.io/css/print.css media=print><link type=text/css rel=stylesheet href=https://minghsu.io/css/poole.css><link type=text/css rel=stylesheet href=https://minghsu.io/css/syntax.css><link type=text/css rel=stylesheet href=https://minghsu.io/css/hyde.css><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Abril+Fatface|PT+Sans:400,400i,700"><link rel=apple-touch-icon-precomposed sizes=144x144 href=/apple-touch-icon-144-precomposed.png><link rel="shortcut icon" href=/favicon.png></head><style>pre,code{white-space:pre;overflow-x:scroll}.hljs{display:inline-block;overflow-x:scroll;padding-right:100%;background:0 0;color:#fff;-webkit-text-size-adjust:none;min-width:2300px}</style><style>@import "https://fonts.googleapis.com/css?family=Open+Sans";body{font-family:open sans,sans-serif}.searchTerm{border-radius:5px;width:100%;border:1px solid #00b4cc;padding:8px 12px}</style><script async src="https://www.googletagmanager.com/gtag/js?id=G-96ZZVQWZLF"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag('js',new Date),gtag('config','G-96ZZVQWZLF')</script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.6.0/highlight.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.6.0/languages/go.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.6.0/languages/yaml.min.js></script><script>hljs.initHighlightingOnLoad()</script><body><aside class=sidebar><div class=container><div class=sidebar-about><a href=https://minghsu.io/><h1>Ming's Site</h1></a><p class=lead><a href=https://github.com/minghsu0107><i class="fab fa-github"></i></a>&nbsp;&nbsp;<a href=https://linkedin.com/in/hao-ming-hsu-178176181> <i class="fab fa-linkedin"></i></a><br><a href=/about>Hao-Ming Hsu (許浩鳴)</a><br>Learn by Doing.<br><a href=https://github.com/minghsu0107>@minghsu0107</a></p></div><nav><ul class=sidebar-nav><li><a href=/about>About</a></li><li><a href=/categories>Categories</a></li><li><a href=/tags>Tags</a></li></ul></nav><div style="margin:0 auto"><form action=https://minghsu.io/search><input placeholder=search class=searchTerm id=search-query name=s></form></div><br><p>&copy; 2022. All rights reserved.</p></div></aside><main class="content container"><div class=post><h1>[K8s] Learn Kubernetes HA Architecture with Hands-On Example</h1><time datetime=2021-04-27T02:27:23+0800 class=post-date>Tue, Apr 27, 2021 &#183; <span class=read-time>3 min read</span></time><div class=chip><a href=https://minghsu.io/tags/k8s//>K8s</a></div><div class=chip><a href=https://minghsu.io/tags/ha//>HA</a></div><div class=chip><a href=https://minghsu.io/tags/keepalived//>Keepalived</a></div><br><br><p>The following diagram shows a typical high-availibility Kubernetes cluster with embedded etcd:</p><p><img src=/static/images/FwEzzWV.png alt></p><p>However, HA architecture also brings about another problem - which K8s API server should the client connect to? How to detect a node failure while fowarding traffic in order to achieve high availibility?</p><p>Each of K8s controller plane replicas will run the following components in the following mode:</p><ul><li>etcd instance: all instances will be clustered together using consensus;</li><li>API server: each server will talk to local etcd - all API servers in the cluster will be available;</li><li>controllers, scheduler, and cluster auto-scaler: will use lease mechanism - only one instance of each of them will be active in the cluster;</li><li>add-on manager: each manager will work independently trying to keep add-ons in sync</li></ul><p>But how to determine which K8s API server the client should connect to while ensuring healthiness of the backend servers? Simply adding mulitple DNS A records does not solve the problem since DNS server could not check server healthiness in real time. A reverse proxy with upstream health check is still not good enough because it would become a single-point-of-failure.</p><p><strong>The concept of virtual ip comes to the rescue</strong>.</p><p>To achieve high availibility, we will use Keepalived, a LVS (Linux Virtual Server) solution based on VRRP protocol. A LVS service contains a master and multiple backup servers while exposing a virtual ip to outside as a whole. The virtual ip will be pointed to the master server. The master server will send heartbeats to backup servers. Once backup servers are not receiving heartbeats, one backup server will take over the virtual ip, ie. the virtual ip will &ldquo;float&rdquo; to that backup server.</p><p>To sum up, we have the following architecture:</p><p><img src=/static/images/FrwyxCQ.png alt></p><ol><li>A floating vip maps to three keepalived servers (one master and two backups). Each keepalived server runs on a K8s controller plane replica.</li><li>When keepalived master server fails, vip floats to another backup server automatically.</li><li>HAProxy load-balances traffic to three K8s API servers.</li></ol><p>The following section is hands-on tutorial that implements the above architecture.</p><h2 id=settings>Settings</h2><ul><li>Three controller plane nodes in private network: <code>172.16.0.0/16</code></li><li>Node private IPs: <code>172.16.217.171</code>, <code>172.16.217.172</code>, <code>172.16.217.173</code></li><li>Virtual IP: <code>172.16.100.100</code>, <code>172.16.100.101</code></li></ul><h2 id=usage>Usage</h2><p>You can find full source code on <a href=https://github.com/minghsu0107/k8s-ha>my Github</a>.</p><p>HAProxy configuration for load balancing on K8s API servers (<code>haproxy.cfg</code>):</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>global
    log /dev/log  local0 warning
    maxconn     <span style=color:#ae81ff>4000</span>
    daemon
  
defaults
  log global
  option  httplog
  option  dontlognull
  timeout connect <span style=color:#ae81ff>5000</span>
  timeout client <span style=color:#ae81ff>50000</span>
  timeout server <span style=color:#ae81ff>50000</span>


frontend kube-apiserver
  bind *:<span style=color:#e6db74>&#34;</span>$HAPROXY_PORT<span style=color:#e6db74>&#34;</span>
  mode tcp
  option tcplog
  default_backend kube-apiserver

backend kube-apiserver
  mode tcp
  option tcp-check
  balance roundrobin
  default-server inter 10s downinter 5s rise <span style=color:#ae81ff>2</span> fall <span style=color:#ae81ff>2</span> slowstart 60s maxconn <span style=color:#ae81ff>250</span> maxqueue <span style=color:#ae81ff>256</span> weight <span style=color:#ae81ff>100</span>
  server kube-apiserver-1 172.16.217.171:6443 check <span style=color:#75715e># simple http health check</span>
  server kube-apiserver-1 172.16.217.172:6443 check
  server kube-apiserver-1 172.16.217.173:6443 check
</code></pre></div><p>Keepalived configuration (<code>keepalived.conf</code>):</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>global_defs <span style=color:#f92672>{</span>
  default_interface <span style=color:#f92672>{{</span> KEEPALIVED_INTERFACE <span style=color:#f92672>}}</span>
<span style=color:#f92672>}</span>

vrrp_script chk_haproxy <span style=color:#f92672>{</span>
    <span style=color:#75715e># check haproxy</span>
    script <span style=color:#e6db74>&#34;/bin/bash -c &#39;if [[ </span><span style=color:#66d9ef>$(</span>netstat -nlp | grep 7443<span style=color:#66d9ef>)</span><span style=color:#e6db74> ]]; then exit 0; else exit 1; fi&#39;&#34;</span>
    interval <span style=color:#ae81ff>2</span> <span style=color:#75715e># check every two seconds</span>
    weight <span style=color:#ae81ff>11</span>
<span style=color:#f92672>}</span>

vrrp_instance VI_1 <span style=color:#f92672>{</span>
  interface <span style=color:#f92672>{{</span> KEEPALIVED_INTERFACE <span style=color:#f92672>}}</span>

  state <span style=color:#f92672>{{</span> KEEPALIVED_STATE <span style=color:#f92672>}}</span>
  virtual_router_id <span style=color:#f92672>{{</span> KEEPALIVED_ROUTER_ID <span style=color:#f92672>}}</span>
  priority <span style=color:#f92672>{{</span> KEEPALIVED_PRIORITY <span style=color:#f92672>}}</span>
  advert_int <span style=color:#ae81ff>2</span>

  unicast_peer <span style=color:#f92672>{</span>
    <span style=color:#f92672>{{</span> KEEPALIVED_UNICAST_PEERS <span style=color:#f92672>}}</span>
  <span style=color:#f92672>}</span>

  virtual_ipaddress <span style=color:#f92672>{</span>
    <span style=color:#f92672>{{</span> KEEPALIVED_VIRTUAL_IPS <span style=color:#f92672>}}</span>
  <span style=color:#f92672>}</span>

  authentication <span style=color:#f92672>{</span>
    auth_type PASS
    auth_pass <span style=color:#f92672>{{</span> KEEPALIVED_PASSWORD <span style=color:#f92672>}}</span>
  <span style=color:#f92672>}</span>

  track_script <span style=color:#f92672>{</span>
    chk_haproxy
  <span style=color:#f92672>}</span>

  <span style=color:#f92672>{{</span> KEEPALIVED_NOTIFY <span style=color:#f92672>}}</span>
<span style=color:#f92672>}</span>
</code></pre></div><p>This configure keepalived server to check if HAProxy is healthy every 2 seconds. Some important environment variables:</p><ul><li><code>KEEPALIVED_INTERFACE</code>: Keepalived network interface. Defaults to eth0</li><li><code>KEEPALIVED_PASSWORD</code>: Keepalived password. Defaults to d0cker</li><li><code>KEEPALIVED_PRIORITY</code> Keepalived node priority. Defaults to 150</li><li><code>KEEPALIVED_ROUTER_ID</code> Keepalived virtual router ID. Defaults to 51</li><li><code>KEEPALIVED_UNICAST_PEERS</code> Keepalived unicast peers. Defaults to <code>192.168.1.10</code>, <code>192.168.1.11</code></li><li><code>KEEPALIVED_VIRTUAL_IPS</code>: Keepalived virtual IPs. Defaults to <code>192.168.1.231</code>, <code>192.168.1.232</code></li><li><code>KEEPALIVED_NOTIFY</code>: Script to execute when node state change. Defaults to <code>/container/service/keepalived/assets/notify.sh</code></li><li><code>KEEPALIVED_STATE</code>: The starting state of keepalived; it can either be <code>MASTER</code> or <code>BACKUP</code>.</li></ul><p>We will use docker to run HAProxy and on each K8s controller plane replicas.</p><p>On first node:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>docker run -d --net<span style=color:#f92672>=</span>host --volume <span style=color:#66d9ef>$(</span>pwd<span style=color:#66d9ef>)</span>/config/haproxy:/usr/local/etc/haproxy <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    -e HAPROXY_PORT<span style=color:#f92672>=</span><span style=color:#ae81ff>7443</span> <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    haproxy:2.3-alpine
docker run -d --cap-add<span style=color:#f92672>=</span>NET_ADMIN --cap-add<span style=color:#f92672>=</span>NET_BROADCAST --cap-add<span style=color:#f92672>=</span>NET_RAW --net<span style=color:#f92672>=</span>host <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    --volume <span style=color:#66d9ef>$(</span>pwd<span style=color:#66d9ef>)</span>/config/keepalived/keepalived.conf:/container/service/keepalived/assets/keepalived.conf <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    -e KEEPALIVED_INTERFACE<span style=color:#f92672>=</span>eth0 <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    -e KEEPALIVED_PASSWORD<span style=color:#f92672>=</span>pass <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    -e KEEPALIVED_STATE<span style=color:#f92672>=</span>MASTER <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    -e KEEPALIVED_VIRTUAL_IPS<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;#PYTHON2BASH:[&#39;172.16.100.100&#39;, &#39;172.16.100.101&#39;]&#34;</span> <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    -e KEEPALIVED_UNICAST_PEERS<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;#PYTHON2BASH:[&#39;172.16.217.171&#39;, &#39;172.16.217.172&#39;, &#39;172.16.217.173&#39;]&#34;</span> <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    osixia/keepalived:2.0.20 --copy-service
</code></pre></div><p>On second node:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>docker run -d --net<span style=color:#f92672>=</span>host --volume <span style=color:#66d9ef>$(</span>pwd<span style=color:#66d9ef>)</span>/config/haproxy:/usr/local/etc/haproxy <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    -e HAPROXY_PORT<span style=color:#f92672>=</span><span style=color:#ae81ff>7443</span> <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    haproxy:2.3-alpine
    --volume <span style=color:#66d9ef>$(</span>pwd<span style=color:#66d9ef>)</span>/config/keepalived/keepalived.conf:/container/service/keepalived/assets/keepalived.conf <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>docker run -d --cap-add<span style=color:#f92672>=</span>NET_ADMIN --cap-add<span style=color:#f92672>=</span>NET_BROADCAST --cap-add<span style=color:#f92672>=</span>NET_RAW --net<span style=color:#f92672>=</span>host <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    -e KEEPALIVED_INTERFACE<span style=color:#f92672>=</span>eth0 <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    -e KEEPALIVED_PASSWORD<span style=color:#f92672>=</span>pass <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    -e KEEPALIVED_STATE<span style=color:#f92672>=</span>BACKUP <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    -e KEEPALIVED_VIRTUAL_IPS<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;#PYTHON2BASH:[&#39;172.16.100.100&#39;, &#39;172.16.100.101&#39;]&#34;</span> <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    -e KEEPALIVED_UNICAST_PEERS<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;#PYTHON2BASH:[&#39;172.16.217.171&#39;, &#39;172.16.217.172&#39;, &#39;172.16.217.173&#39;]&#34;</span> <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    osixia/keepalived:2.0.20 --copy-service
</code></pre></div><p>On third node:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>docker run -d --net<span style=color:#f92672>=</span>host --volume <span style=color:#66d9ef>$(</span>pwd<span style=color:#66d9ef>)</span>/config/haproxy:/usr/local/etc/haproxy <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    -e HAPROXY_PORT<span style=color:#f92672>=</span><span style=color:#ae81ff>7443</span> <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    haproxy:2.3-alpine
docker run -d --cap-add<span style=color:#f92672>=</span>NET_ADMIN --cap-add<span style=color:#f92672>=</span>NET_BROADCAST --cap-add<span style=color:#f92672>=</span>NET_RAW --net<span style=color:#f92672>=</span>host <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    --volume <span style=color:#66d9ef>$(</span>pwd<span style=color:#66d9ef>)</span>/config/keepalived/keepalived.conf:/container/service/keepalived/assets/keepalived.conf <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    -e KEEPALIVED_INTERFACE<span style=color:#f92672>=</span>eth0 <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    -e KEEPALIVED_PASSWORD<span style=color:#f92672>=</span>pass <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    -e KEEPALIVED_STATE<span style=color:#f92672>=</span>BACKUP <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    -e KEEPALIVED_VIRTUAL_IPS<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;#PYTHON2BASH:[&#39;172.16.100.100&#39;, &#39;172.16.100.101&#39;]&#34;</span> <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    -e KEEPALIVED_UNICAST_PEERS<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;#PYTHON2BASH:[&#39;172.16.217.171&#39;, &#39;172.16.217.172&#39;, &#39;172.16.217.173&#39;]&#34;</span> <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    osixia/keepalived:2.0.20 --copy-service
</code></pre></div><p>Finally, point your dns to either <code>172.16.100.100</code> or <code>172.16.100.101</code>. From now on, a request with url <code>&lt;https://your.domain.com:7443></code> will be resolved to <code>https://&lt;172.16.100.100|172.16.100.101>:7443</code>, rounted to the current keepalived master, and eventually sent to one of the three K8s API servers by HAProxy.</p><h2 id=reference>Reference</h2><ul><li><a href=https://kubernetes.io/docs/tasks/administer-cluster/highly-available-master/>https://kubernetes.io/docs/tasks/administer-cluster/highly-available-master/</a></li><li><a href=https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/high-availability/>https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/high-availability/</a></li><li><a href=https://www.kubernetes.org.cn/6964.html>https://www.kubernetes.org.cn/6964.html</a></li><li><a href=https://www.mdeditor.tw/pl/pRgX/zh-tw>https://www.mdeditor.tw/pl/pRgX/zh-tw</a></li></ul></div><h2>Read More</h2><ul><li><a href=https://minghsu.io/posts/droneci-argocd/>[K8s] 使用 DroneCI 與 ArgoCD 實現 K8s 自動整合部署</a></li><li><a href=https://minghsu.io/posts/integrate-traefik-with-cloud-ingress/>[K8s] All You Need to Know to Integrate Traefik with Cloud Ingress</a></li></ul><h2>Comments</h2><script src=https://utteranc.es/client.js repo=minghsu0107/blog issue-term=pathname theme=github-light crossorigin=anonymous async></script></main></body></html>